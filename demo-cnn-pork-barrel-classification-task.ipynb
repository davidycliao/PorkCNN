{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b65dfbdc-bb80-4bd4-8248-dd06483222cd",
   "metadata": {},
   "source": [
    "# Lour's Pork Barrel Classifier (羅老師肉桶文本分類器)🐖\n",
    "## Convolutional Neural Networks for Pork Barrel Project Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8005d5a-f938-4c26-86d5-592408152d08",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "\n",
    "### Stage 1: Libaries & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca92ba3-7480-418f-91e0-d2beea2d10af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# built-in library\n",
    "import math\n",
    "import re\n",
    "import collections\n",
    "import zipfile\n",
    "from itertools import chain\n",
    "\n",
    "# ML & Deep Learning/ NLP toolkit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd77e05-355a-422f-87db-2cf77cba3bdd",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "\n",
    "### Stage 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b57b9c9-443e-4e26-bda2-15f6877845d5",
   "metadata": {},
   "source": [
    "#### (1) Read file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1973cfb-73d4-4717-a67a-a4e8a0c9edb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Pork Bill - LY.csv',encoding='utf-8')\n",
    "df['text'] =  df['Title'] + df['Content'].fillna(df['Title'])\n",
    "data = df[['text', 'pork_bill']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282b9fad-45f1-4325-97a1-4d612608e73e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6160785-9522-4404-8f77-6df941869cde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\" Pork Legislation\", data['pork_bill'].value_counts()[0],'\\n', \n",
    "      \"None-Pork Legislation\", data['pork_bill'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d677d-e200-40e6-9252-130eb02fc682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T17:01:03.001989Z",
     "iopub.status.busy": "2021-05-16T17:01:03.001801Z",
     "iopub.status.idle": "2021-05-16T17:01:03.004600Z",
     "shell.execute_reply": "2021-05-16T17:01:03.003789Z",
     "shell.execute_reply.started": "2021-05-16T17:01:03.001969Z"
    }
   },
   "source": [
    "#### (2) Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e8b54-7f75-4ca6-a0d0-9872b1522e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import jieba\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "def jieba_cut(filename):\n",
    "    \"\"\"\n",
    "    cut Chinese and remove stop words\n",
    "    Reference: https://www.cnblogs.com/Luv-GEM/p/10836454.html\n",
    "    Stopwords: https://www.kaggle.com/rikdifos/english-and-chinese-stopwords?select=cn_stopwords.txt\n",
    "    \"\"\"\n",
    "    stop_list = [i.strip() for i in open('cn_stopwords.txt','r',encoding='utf-8')]  \n",
    "    news_cut = []\n",
    "    news_list = []\n",
    "    for line in filename:    \n",
    "        if line:\n",
    "            news_cut = list(jieba.cut(''.join(line),cut_all=False,HMM=True))  \n",
    "            news_list.append([word.strip() for word in news_cut if word not in stop_list and len(word.strip())>0]) \n",
    "    news_list = list(chain.from_iterable(news_list))  \n",
    "    return news_list\n",
    "\n",
    "def clearPucts(context):\n",
    "    \"\"\"\n",
    "    remove punctuation\n",
    "    ref: https://chenyuzuoo.github.io/posts/28001/\n",
    "    \"\"\"\n",
    "    context = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\", context)\n",
    "    context = re.sub(\"[【】╮╯▽╰╭★→「」]+\",\"\", context)\n",
    "    context = re.sub(\"！，❤。～《》：（）【】「」？”“；：、\",\"\",context)\n",
    "    context = re.sub(\"\\s\",\"\",context)\n",
    "    return context\n",
    "\n",
    "def seg_char(sent):\n",
    "    \"\"\"\n",
    "    cut Chinese and remove stop words\n",
    "    ref: https://blog.csdn.net/renyuanfang/article/details/86487367\n",
    "    \"\"\"\n",
    "    # 首先分割 英文 以及英文和标点\n",
    "    pattern_char_1 = re.compile(r'([\\W])')\n",
    "    parts = pattern_char_1.split(sent)\n",
    "    parts = [p for p in parts if len(p.strip())>0]\n",
    "    # 分割中文\n",
    "    pattern = re.compile(r'([\\u4e00-\\u9fa5])')\n",
    "    chars = pattern.split(sent)\n",
    "    chars = [w for w in chars if len(w.strip())>0]\n",
    "    chars = ' '.join(chars)\n",
    "    return chars\n",
    "\n",
    "# import spacy\n",
    "# # python3 -m spacy download zh_core_web_sm\n",
    "# spacy_nlp = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "# data_clean = [clearPucts(text) for text in data.text]\n",
    "# data_clean = [[spacy_nlp(sentence).vector for sentence in data] for data in data_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f4277c-001d-47a4-81d0-f5ac5ec5e5d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_clean = [seg_char(text) for text in [clearPucts(text) for text in data.text]]\n",
    "\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    data_clean, target_vocab_size=2**18)\n",
    "\n",
    "data_inputs = [tokenizer.encode(sentence) for sentence in data_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089e65af-e49c-4d60-962e-a0a826809aa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T17:01:47.611294Z",
     "iopub.status.busy": "2021-05-16T17:01:47.611020Z",
     "iopub.status.idle": "2021-05-16T17:01:47.614208Z",
     "shell.execute_reply": "2021-05-16T17:01:47.613487Z",
     "shell.execute_reply.started": "2021-05-16T17:01:47.611276Z"
    }
   },
   "source": [
    "#### (3) Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b801d231-972c-47e3-83c4-7375c2e11a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LEN = max([len(sentence) for sentence in data_clean])\n",
    "data_inputs = tf.keras.preprocessing.sequence.pad_sequences(data_inputs,\n",
    "                                                            value=0,\n",
    "                                                            padding=\"post\",\n",
    "                                                            maxlen=MAX_LEN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69d90cf-ac3c-4e08-b46b-457d9708d832",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T17:02:28.107037Z",
     "iopub.status.busy": "2021-05-16T17:02:28.106843Z",
     "iopub.status.idle": "2021-05-16T17:02:28.109696Z",
     "shell.execute_reply": "2021-05-16T17:02:28.108954Z",
     "shell.execute_reply.started": "2021-05-16T17:02:28.107017Z"
    }
   },
   "source": [
    "#### (4) Spliting Training/ Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42503355-eea3-4602-ae5a-ea18be84b8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_labels = data.pork_bill.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19235117-f63a-4e06-a102-6efe98c37dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(\n",
    "    data_inputs, data_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"Shape of X Train:\", train_inputs.shape, '\\n'\n",
    "      \"Shape of x Test: \", test_inputs.shape,'\\n'\n",
    "      \"Shape of Y Trian:\", train_labels.shape , '\\n'\n",
    "      \"Shape of y Test: \", test_labels.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f7feb-b93b-4d0b-bcbf-562240a79f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T17:04:13.375644Z",
     "iopub.status.busy": "2021-05-16T17:04:13.375440Z",
     "iopub.status.idle": "2021-05-16T17:04:13.378111Z",
     "shell.execute_reply": "2021-05-16T17:04:13.377464Z",
     "shell.execute_reply.started": "2021-05-16T17:04:13.375623Z"
    },
    "tags": []
   },
   "source": [
    "-------------------------\n",
    "\n",
    "\n",
    "### Stage 3: Model Specification and Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0e74bf-eaf4-4043-8d23-88291d8ea344",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T17:13:18.807725Z",
     "iopub.status.busy": "2021-05-16T17:13:18.807498Z",
     "iopub.status.idle": "2021-05-16T17:13:18.810574Z",
     "shell.execute_reply": "2021-05-16T17:13:18.809625Z",
     "shell.execute_reply.started": "2021-05-16T17:13:18.807701Z"
    }
   },
   "source": [
    "#### (1) Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f18f9b1-5f4d-4d0a-baf4-2eebed7f34f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DCNN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 emb_dim=128,\n",
    "                 nb_filters=50,\n",
    "                 FFN_units=512,\n",
    "                 nb_classes=2,\n",
    "                 dropout_rate=0.1,\n",
    "                 training=False,\n",
    "                 name=\"dcnn\"):\n",
    "        super(DCNN, self).__init__(name=name)\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size, \n",
    "                                          emb_dim)\n",
    "        self.bigram = layers.Conv1D(filters=nb_filters, \n",
    "                                    kernel_size=2,\n",
    "                                    padding=\"valid\",\n",
    "                                    activation=\"relu\")\n",
    "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
    "                                     kernel_size=3,\n",
    "                                     padding=\"valid\",\n",
    "                                     activation=\"relu\")\n",
    "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
    "                                      kernel_size=4,\n",
    "                                      padding=\"valid\",\n",
    "                                      activation=\"relu\")\n",
    "        self.pool = layers.GlobalMaxPool1D() # no training variable so we can\n",
    "                                             # use the same layer for each\n",
    "                                             # pooling step\n",
    "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
    "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
    "        if nb_classes == 2:\n",
    "            self.last_dense = layers.Dense(units=1,\n",
    "                                           activation=\"sigmoid\")\n",
    "        else:\n",
    "            self.last_dense = layers.Dense(units=nb_classes,\n",
    "                                           activation=\"softmax\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        x = self.embedding(inputs)\n",
    "        x_1 = self.bigram(x)\n",
    "        x_1 = self.pool(x_1)\n",
    "        x_2 = self.trigram(x)\n",
    "        x_2 = self.pool(x_2)\n",
    "        x_3 = self.fourgram(x)\n",
    "        x_3 = self.pool(x_3)\n",
    "        \n",
    "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
    "        merged = self.dense_1(merged)\n",
    "        merged = self.dropout(merged, training)\n",
    "        output = self.last_dense(merged)        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc02e93-3a0e-4c1c-b488-b2db98b53824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1819 # tokenizer.vocab_size\n",
    "EMB_DIM = 200\n",
    "NB_FILTERS = 100\n",
    "FFN_UNITS = 256\n",
    "NB_CLASSES = 2 #len(set(train_labels))\n",
    "DROPOUT_RATE = 0.2\n",
    "BATCH_SIZE = 32\n",
    "NB_EPOCHS = 150\n",
    "\n",
    "Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n",
    "            emb_dim=EMB_DIM,\n",
    "            nb_filters=NB_FILTERS,\n",
    "            FFN_units=FFN_UNITS,\n",
    "            nb_classes=NB_CLASSES,\n",
    "            dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec8f51-6ed8-49fa-9d5e-c6929184bdf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T18:43:59.279424Z",
     "iopub.status.busy": "2021-05-16T18:43:59.279202Z",
     "iopub.status.idle": "2021-05-16T18:43:59.282718Z",
     "shell.execute_reply": "2021-05-16T18:43:59.281823Z",
     "shell.execute_reply.started": "2021-05-16T18:43:59.279399Z"
    }
   },
   "source": [
    "#### (2) Compile and Summary of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78131d8a-fbb7-4cf0-9cfc-d36bf10b8a34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Dcnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "Dcnn.build(input_shape = (123 , EMB_DIM)) # (train_inputs.shape[1] , EMB_DIM)\n",
    "Dcnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3880d2a4-2152-43de-bad3-34e67e97469e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### (3) Check Point Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4115bec-233a-4abc-b081-05f526c4687b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoint_recode\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(\"Checkpoint Located!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d70667-275f-40c0-bd71-6b47e9722798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T17:47:13.442664Z",
     "iopub.status.busy": "2021-05-16T17:47:13.442381Z",
     "iopub.status.idle": "2021-05-16T17:47:13.448371Z",
     "shell.execute_reply": "2021-05-16T17:47:13.446970Z",
     "shell.execute_reply.started": "2021-05-16T17:47:13.442620Z"
    }
   },
   "source": [
    "-------------------------\n",
    "\n",
    "### Stage 4: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc975047-5a58-46dc-b427-262796d9b625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf0cade-2c45-43b2-9782-6a8c6e570153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Dcnn.fit(train_inputs,\n",
    "         train_labels,\n",
    "         validation_data=(test_inputs, test_labels),\n",
    "         batch_size=BATCH_SIZE,\n",
    "         epochs=NB_EPOCHS,\n",
    "         callbacks=[early_stop])\n",
    "ckpt_manager.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0ac256-ab81-4ff5-8430-48f8bba50126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T18:23:25.926977Z",
     "iopub.status.busy": "2021-05-16T18:23:25.926754Z",
     "iopub.status.idle": "2021-05-16T18:23:25.931072Z",
     "shell.execute_reply": "2021-05-16T18:23:25.930041Z",
     "shell.execute_reply.started": "2021-05-16T18:23:25.926952Z"
    }
   },
   "source": [
    "-------------------------\n",
    "\n",
    "### Stage 5: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58099cc1-19e0-443a-b960-7ae4d67344d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(Dcnn.history.history)\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a760f-b388-4051-a78d-295bce1f214a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losses[['accuracy','val_accuracy']].plot()\n",
    "losses[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44300a6c-8da8-43cd-ada0-208a99b6b9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17760825-eb35-4f8c-88a0-45e94387c08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation_model = Dcnn.evaluate(test_inputs, test_labels, batch_size=BATCH_SIZE)\n",
    "print(evaluation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3f93d-4398-418c-b511-69594874cc5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(confusion_matrix(test_labels,predictions))\n",
    "predictions = Dcnn.predict(test_inputs)\n",
    "predictions = np.where(predictions >0.8 , 1, 0)\n",
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767688b-bfc8-4dc4-b8ec-2252f7791534",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = pd.DataFrame(confusion_matrix(test_labels,predictions), \n",
    "             columns=['Predictions: Not Pork(0)','Predictions:Pork(1)'])\n",
    "t.index = ['Acutal: Not Pork(0)', 'Acutal:Not Pork (1)']\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0416d6f-5e46-47c9-abad-f344bea7a94a",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "\n",
    "### Stage 6: Try the Model with New Data and Export an End-to-end Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b9a6e-0130-4af2-88e5-efe91cf9f348",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-16T22:53:41.558105Z",
     "iopub.status.busy": "2021-05-16T22:53:41.557872Z",
     "iopub.status.idle": "2021-05-16T22:53:41.560984Z",
     "shell.execute_reply": "2021-05-16T22:53:41.560122Z",
     "shell.execute_reply.started": "2021-05-16T22:53:41.558080Z"
    }
   },
   "source": [
    "#### (1) Test New Dataset from 200 samples from Leislative Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632bf33e-1df7-46c5-9a67-ab7141a949c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def as_num(x):\n",
    "    \"\"\"\n",
    "    keep 10 decimals\n",
    "    \"\"\"\n",
    "    y = '{:.15f}'.format(x) \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813dab9c-dd1b-4d88-ad68-408fc91c2101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# test the trined model using new text from 200 samples from Leislative Questions\n",
    "LQ6 = pd.read_csv('data/interpellation_ly_6th.csv')\n",
    "\n",
    "# select text with number of charecters within EMB_DIM; len(sub_set) = 11162\n",
    "sample_df = LQ6.loc[[len(char_num) for char_num in LQ6.title if len(char_num) < MAX_LEN], ['title', 'topic']].reset_index(drop=True)\n",
    "\n",
    "# randomly subsect 200 rows \n",
    "random.seed(4)\n",
    "sample_df = LQ6.loc[random.sample(range(len(LQ6)), 200), ['title', 'topic', 'category', 'keywords', 'ques_type']]\n",
    "sub_set = [seg_char(text) for text in [clearPucts(text) for text in sample_df.title]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc06a7-27d7-4007-949d-f7df81246e25",
   "metadata": {},
   "source": [
    "##### Top 10 of 200 Sampled Legislative Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b618c9-8c4b-40ec-a396-b4679233197e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {'Pork Value(Constituency Interest)':[as_num(Dcnn(np.array([tokenizer.encode(line)]), training=True).numpy()[0][0]) for line in sub_set],\n",
    "     'Legislative Questions ': sample_df.title,\n",
    "     'Topic': sample_df.topic,\n",
    "     'Key Word':sample_df.keywords}).sort_values(by=['Pork Value(Constituency Interest)'], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d4b15-3e05-427d-a664-8c8ce4e6622c",
   "metadata": {},
   "source": [
    "##### Last 10 Rows of 200 Sampled Legislative Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a7336-dc9d-4883-b919-b19611b5ad39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {'Pork Value(Constituency Interest)':[as_num(Dcnn(np.array([tokenizer.encode(line)]), training=True).numpy()[0][0]) for line in sub_set],\n",
    "     'Legislative Questions ': sample_df.title,\n",
    "     'Topic': sample_df.topic,\n",
    "     'Key Word':sample_df.keywords}).sort_values(by=['Pork Value(Constituency Interest)'], ascending = False).tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc01475-847a-408f-9972-ac02e7aa4721",
   "metadata": {},
   "source": [
    "#### (2) Export an End-to-end Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196028d0-edfe-434f-a173-4ccaa688faaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071291d0-c5bb-48de-adb2-f8b2bb3bb542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get model (Sequential, Functional Model, or Model subclass)\n",
    "Dcnn.save('lour_pork_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac46183-b841-469b-8897-1fea2922e445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('lour_pork_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
